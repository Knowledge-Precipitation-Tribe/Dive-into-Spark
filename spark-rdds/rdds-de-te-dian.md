# RDDs 的特点

由于RDD是一个只读的分区数据集，无法直接对数据集进行修改，只能通过RDD自带的转化操作，由一个RDD得到一个新的RDD，而这个新的RDD就是其他RDD的衍生物，也就肯定包含了其他RDD的信息。

基于这样一个特性，RDD之间必定存在依赖，这使得RDDs会形成一个有**向无环图DAG，**而这个DAG就像是记录这一系列转化过程的记录者，在实际执行时，就可以通过这样的依赖关系进行计算。 

> **注意：RDD还可以将数据集缓存到内存中，使得在多个操作之间可以重用数据集，基于这个特点可以很方便地构建迭代型应用\(图计算、机器学习等\)或者交互式数据分析应用。**



基于这样的介绍，RDD存在以下4个特点：

**1、分区性**

对于每一个RDD，其逻辑上是一个分区的，且是该分区上数据的一个抽象形式，只有在计算的时候通过compute函数得到每个分区的数据，这一点有点像深度学习语言，先构建好计算图，在训练时在传入数据。

![](../.gitbook/assets/image%20%2825%29.png)

也就是说，如果该RDD是通过已存在的文件进行构建的，则compute函数是读取指定文件系统中的数据；如果RDD是通过其他RDD转换来的，则compute函数是执行转换逻辑将其他RDD的数据进行转换。总的来说，**RDD是分区间的，之间产生的依赖关系通过compute函数去操作。**

**2、只读性**

由于RDD是只读的，因此想要改变RDD中的数据集，只能通过RDD的转换创建新的RDD。Spark提供RDD丰富的操作算子，实现一个RDD转化成另一个RDD，如下图所示。

![](../.gitbook/assets/image%20%2828%29.png)

**3、依赖性**

RDDs通过操作算子进行转换，转换得到的新RDD包含了从其他RDDs衍生所必需的信息，RDDs之间维护着这种血缘关系，也称之为依赖。

![](../.gitbook/assets/image%20%2823%29.png)

如图所示，依赖包括两种，一种是_窄依赖_，RDDs之间分区是一一对应的，另一种是_宽依赖_，下游RDD的每个分区与上游RDD\(也称之为父RDD\)的每个分区都有关，是多对多的关系。

**其中对于窄依赖在实际执行过程中会类似于管道一样一气呵成，就是说，多不操作之间不进行存储，在执行完之后再进行存储。**

**4、缓存**

这是Spark中实现加速的一个手段，即对于一个RDD如果被多个RDD所使用的时候\(多个RDD的父RDD\)，可以将这个RDD缓存起来，，该RDD只有在第一次计算的时候根据依赖关系得到分区的数据，在后续其他地方用到时，直接从缓存处取，不需要再重新根据依赖关系进行计算，这样就加速后期的重用。

![](../.gitbook/assets/image%20%2824%29.png)

**CheckPoint**

> 虽然RDD的血缘关系天然地可以实现容错，当RDD的某个分区数据失败或丢失，可以通过血缘关系重建。但是对于长时间迭代型应用来说，随着迭代的进行，RDDs之间的血缘关系会越来越长，一旦在后续迭代过程中出错，则需要通过非常长的血缘关系去重建，势必影响性能。
>
> 为此，RDD支持checkpoint将数据保存到持久化的存储中，这样就可以切断之前的血缘关系，因为checkpoint后的RDD不需要知道它的父RDDs了，它可以从checkpoint处拿到数据。

![](../.gitbook/assets/image%20%2827%29.png)

















